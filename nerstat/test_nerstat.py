# -*- coding:utf-8 -*-

"""
处理空格的部分，原始sentence来自nerstat/boson_phrases.txt.
如果nerstat/boson_phrases.txt里面无空格，则spaceinfo为空
"""

import sys
sys.path.append(".")

import unittest
import nerstat
import demjson
import numpy as np
import json

class find_overlaps(unittest.TestCase):
    def setUp(self):
        # a705f39be129883f0241bf8762d129d8	5665
        self.doc_id = "a705f39be129883f0241bf8762d129d8"
        self.phrase_id = "5665"

    def printnp(self, name, arr):
        print name + ": ",
        for i in arr:
            if type(i) == np.int64:
                print i,
            else:
                print i.decode("utf-8") ,  #("string_escape"),
        print ""

    def printentityinfo(self, name, myentityinfo):
        print name + ": "
        entity      = myentityinfo["entity"]
        entity_type = myentityinfo["entity_type"]
        startpos    = myentityinfo["startpos"]
        endpos      = myentityinfo["endpos"]
        entity_len  = myentityinfo["entity_unicode_len"]

        for i in range(len(entity)):
            print entity[i].decode("utf-8") + "," + entity_type[i] + "," + str(startpos[i]) + "," + str(endpos[i]) + "," + str(entity_len[i])

    # Boson, FNLP, LTP三个工具，在分词时去掉了所有的空格，导致entity的offset值，与corenlp, hanlp, foolnltk不同
    # 影响实体对比的效果。
    # 此函数用于获取sentence中的所用空格的信息，以用来纠正Boson, FNLP, LTP的offset值
    # 输入: 确保str是unicode值
    # 输出: [[index, offset]], index是空格的位置，offset是之后的实体的偏移量
    # 遇到多个连续空格时，只记录最后一个空格的信息
    def getspaceinfo(self, sent):
        if type(sent) == str:
            sent = sent.decode("utf-8")

        spaceinfo = []
        if type(sent) == unicode:

            pre = ""
            offset = 0
            for i in range(len(sent)):
                cur = sent[i]
                if cur == " ":
                    index = i
                    offset = offset + 1
                else:
                    if pre == " ":
                        spaceinfo.append([index, offset])
                pre = cur

        return spaceinfo

    # input: spaceinfo: list generated by getspaceinfo
    #        entityinfo:
    # function: update entityinfo via spaceinfo
    # entityinfo, spaceinfo, 都要从后往前访问

    # list是传引用
    def updateentityoffset(self, spaceinfo, entityinfo):
        startpos = entityinfo["startpos"]
        endpos   = entityinfo["endpos"]

        entity_num = len(startpos)

        space_index  = [a[0] for a in spaceinfo]
        space_index.append(9999)
        space_offset = [a[1] for a in spaceinfo]
        space_offset.append(9999)

        space_num = len(space_index) - 1

        i = 0
        for j in range(space_num):

            startrange = space_index[j] - space_offset[j]
            endrange   = space_index[j + 1] - space_offset[j + 1]
            while i < entity_num:
                if startpos[i] <= startrange:
                    i = i + 1
                    continue
                elif startpos[i] > startrange and startpos[i] <= endrange:
                    startpos[i] += space_offset[j]
                    endpos[i]   += space_offset[j]
                    i = i + 1
                else:
                    break

        # print startpos
        # print endpos
        # entityinfo["startpos"] = startpos
        # entityinfo["endpos"] = endpos

        # return entityinfo

    # def test1(self):
    #     myentity = nerstat.find_boson_entity("a09e184cd67d967fc77815f10e6c23d4", "0")
    #     entities = myentity["entity"]
    #     ner_tags = myentity["entity_type"]
    #     entity_unicode_lens = myentity["entity_unicode_len"]
    #     startposes = myentity["startpos"]
    #     endposes   = myentity["endpos"]
    #     num = len(entities)
    #     for i in range(num):
    #         print entities[i].decode("utf-8")
    #         print ner_tags[i]
    #         print startposes[i], endposes[i], entity_unicode_lens[i]

    def test1(self):
        str = "201608@2016_2016-08-22_1471854646_237857 证券代码：835875证券简称：天基新材主办券商：国泰君安 北京天基新材料股份有限公司股权质押公告 本公司及董事会全体成员保证公告内容的真实、准确和完整"
        print self.getspaceinfo(str)

        

    def test2(self):

        jsonObject = {}
        jsonObjArray  = []

        # create phrase_id <--> doc_id dictionary for look up doc_id by phrase_id
        # for boson NER
        myDocDic = nerstat.setupDoc_ID_Dic()

        # 文件个数
        for i in range(1): # there is only 1 file for boson
            # for i in range(22):
            print i
            json_corenlp = demjson.decode_file("./" + "corenlp_"  + str(i) + "_test.json", encoding="utf8")
            json_ltp     = demjson.decode_file("./" + "ltp_"      + str(i) + "_test.json", encoding="utf8")
            json_hanlp   = demjson.decode_file("./" + "hanlp_"    + str(i) + "_test.json", encoding="utf8")
            json_fnlp    = demjson.decode_file("./" + "fnlp_"     + str(i) + "_test.json", encoding="utf8")
            json_fool    = demjson.decode_file("./" + "foolnltk_" + str(i) + "_test.json", encoding="utf8")

            # data array
            data_corenlp = json_corenlp["data"]
            data_ltp     = json_ltp["data"]
            data_hanlp   = json_hanlp["data"]
            data_fnlp    = json_fnlp["data"]
            data_fool    = json_fool["data"]

            number_of_phrase = len(data_ltp)

            for j in range(1):
                # for j in range(3):
                # 合并organization/personal/location, 获取entities
                corenlp_entities_info = nerstat.find_entity_info(data_corenlp[j], "corenlp")
                ltp_entities_info     = nerstat.find_entity_info(data_ltp[j]    , "ltp"    )
                hanlp_entities_info   = nerstat.find_entity_info(data_hanlp[j]  , "hanlp"  )
                fnlp_entities_info    = nerstat.find_entity_info(data_fnlp[j],     "fnlp"  )
                fool_entities_info    = nerstat.find_foolnltk_entity(data_fool[j])





                # ltp: 1, corenlp: 2, hanlp 4, 根据sum来得知两两是否相同

                # 实体名、实体长度、实体起始位置
                # 1. 先比较三者的实体个数是否相等

                # 2. 实际比较
                # 2.1 PERSON 个数，有几个相同
                # 2.2 LOCATION 个数，有几个相同
                # 2.3 ORGANIZATION个数，有几个相同

                # 通过set的 &, in, not in来处理

                phrase_id = corenlp_entities_info["phrase_id"]

                # ----------------------------------------------------------
                doc_id, sentence = myDocDic[phrase_id]
                boson_entities_info = nerstat.find_boson_entity(doc_id, phrase_id)
                # ----------------------------------------------------------


                # update space info
                spaceinfo = self.getspaceinfo(sentence)
                # ltp_entities_info   = self.updateentityoffset(spaceinfo, ltp_entities_info)
                # fnlp_entities_info  = self.updateentityoffset(spaceinfo, fnlp_entities_info)
                # boson_entities_info = self.updateentityoffset(spaceinfo, boson_entities_info)
                self.updateentityoffset(spaceinfo, ltp_entities_info)
                self.updateentityoffset(spaceinfo, fnlp_entities_info)
                self.updateentityoffset(spaceinfo, boson_entities_info)


                print "test verification 0"

                self.printentityinfo("corenlp", corenlp_entities_info)
                self.printentityinfo("ltp", ltp_entities_info)
                self.printentityinfo("hanlp", hanlp_entities_info)
                self.printentityinfo("fnlp", fnlp_entities_info)
                self.printentityinfo("fool", fool_entities_info)
                self.printentityinfo("boson", boson_entities_info)

                np_entity_corenlp = np.array(corenlp_entities_info["entity"])
                np_entity_ltp     = np.array(ltp_entities_info["entity"])
                np_entity_hanlp   = np.array(hanlp_entities_info["entity"])
                np_entity_fnlp    = np.array(fnlp_entities_info["entity"])
                np_entity_fool    = np.array(fool_entities_info["entity"])
                np_entity_boson   = np.array(boson_entities_info["entity"])

                np_type_corenlp = np.array(corenlp_entities_info["entity_type"])
                np_type_ltp     = np.array(ltp_entities_info["entity_type"])
                np_type_hanlp   = np.array(hanlp_entities_info["entity_type"])
                np_type_fnlp    = np.array(fnlp_entities_info["entity_type"])
                np_type_fool    = np.array(fool_entities_info["entity_type"])
                np_type_boson   = np.array(boson_entities_info["entity_type"])

                # for the overlap of entity between corenlp, ltp and hanlp
                np_startpos_corenlp = np.array(corenlp_entities_info["startpos"])
                np_startpos_ltp     = np.array(ltp_entities_info["startpos"])
                np_startpos_hanlp   = np.array(hanlp_entities_info["startpos"])
                np_startpos_fnlp    = np.array(fnlp_entities_info["startpos"])
                np_startpos_fool    = np.array(fool_entities_info["startpos"])
                np_startpos_boson   = np.array(boson_entities_info["startpos"])

                np_endpos_corenlp = np.array(corenlp_entities_info["endpos"])
                np_endpos_ltp     = np.array(ltp_entities_info["endpos"])
                np_endpos_hanlp   = np.array(hanlp_entities_info["endpos"])
                np_endpos_fnlp    = np.array(fnlp_entities_info["endpos"])
                np_endpos_fool    = np.array(fool_entities_info["endpos"])
                np_endpos_boson   = np.array(boson_entities_info["endpos"])

                np_entitylen_corenlp = np.array(corenlp_entities_info["entity_unicode_len"])
                np_entitylen_ltp     = np.array(ltp_entities_info["entity_unicode_len"])
                np_entitylen_hanlp   = np.array(hanlp_entities_info["entity_unicode_len"])
                np_entitylen_fnlp    = np.array(fnlp_entities_info["entity_unicode_len"])
                np_entitylen_fool    = np.array(fool_entities_info["entity_unicode_len"])
                np_entitylen_boson   = np.array(boson_entities_info["entity_unicode_len"])

                print "first verification"
                print "-------------corenlp----------------"
                self.printnp( "   np_entity_corenlp: ", np_entity_corenlp    )
                self.printnp( "     np_type_corenlp: ", np_type_corenlp      )
                self.printnp( " np_startpos_corenlp: ", np_startpos_corenlp  )
                self.printnp( "   np_endpos_corenlp: ", np_endpos_corenlp    )
                self.printnp( "np_entitylen_corenlp: ", np_entitylen_corenlp )

                print "-------------ltp----------------"
                self.printnp( "   np_entity_ltp: ", np_entity_ltp     )
                self.printnp( "     np_type_ltp: ", np_type_ltp       )
                self.printnp( " np_startpos_ltp: ", np_startpos_ltp   )
                self.printnp( "   np_endpos_ltp: ", np_endpos_ltp     )
                self.printnp( "np_entitylen_ltp: ", np_entitylen_ltp  )

                print "-------------hanlp----------------"
                self.printnp( "   np_entity_hanlp: ", np_entity_hanlp       )
                self.printnp( "     np_type_hanlp: ", np_type_hanlp         )
                self.printnp( " np_startpos_hanlp: ", np_startpos_hanlp     )
                self.printnp( "   np_endpos_hanlp: ", np_endpos_hanlp       )
                self.printnp( "np_entitylen_hanlp: ", np_entitylen_hanlp    )

                print "-------------fnlp----------------"
                self.printnp( "   np_entity_fnlp: ", np_entity_fnlp    )
                self.printnp( "     np_type_fnlp: ", np_type_fnlp      )
                self.printnp( " np_startpos_fnlp: ", np_startpos_fnlp  )
                self.printnp( "   np_endpos_fnlp: ", np_endpos_fnlp    )
                self.printnp( "np_entitylen_fnlp: ", np_entitylen_fnlp )

                print "-------------fool----------------"
                self.printnp( "   np_entity_fool: ", np_entity_fool     )
                self.printnp( "     np_type_fool: ", np_type_fool       )
                self.printnp( " np_startpos_fool: ", np_startpos_fool   )
                self.printnp( "   np_endpos_fool: ", np_endpos_fool     )
                self.printnp( "np_entitylen_fool: ", np_entitylen_fool  )

                print "-------------boson----------------"
                self.printnp( "   np_entity_boson: ", np_entity_boson    )
                self.printnp( "     np_type_boson: ", np_type_boson      )
                self.printnp( " np_startpos_boson: ", np_startpos_boson  )
                self.printnp( "   np_endpos_boson: ", np_endpos_boson    )
                self.printnp( "np_entitylen_boson: ", np_entitylen_boson )

                subJsonObject = {}
                subJsonObject["phrase_id"] =  phrase_id


                # 统计每个NER中PERSON、LOCATION, ORGANIZATION的个数

                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                c_person_indexes       = nerstat.find_all_index(np_type_corenlp, "PERSON")
                c_location_indexes     = nerstat.find_all_index(np_type_corenlp, "LOCATION")
                c_organization_indexes = nerstat.find_all_index(np_type_corenlp, "ORGANIZATION")

                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                l_person_indexes       = nerstat.find_all_index(np_type_ltp, "PERSON")
                l_location_indexes     = nerstat.find_all_index(np_type_ltp, "LOCATION")
                l_organization_indexes = nerstat.find_all_index(np_type_ltp, "ORGANIZATION")

                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                h_person_indexes       = nerstat.find_all_index(np_type_hanlp, "PERSON")
                h_location_indexes     = nerstat.find_all_index(np_type_hanlp, "LOCATION")
                h_organization_indexes = nerstat.find_all_index(np_type_hanlp, "ORGANIZATION")

                # FNLP
                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                f_person_indexes       = nerstat.find_all_index(np_type_fnlp, "PERSON")
                f_location_indexes     = nerstat.find_all_index(np_type_fnlp, "LOCATION")
                f_organization_indexes = nerstat.find_all_index(np_type_fnlp, "ORGANIZATION")

                # foolnltk
                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                o_person_indexes        = nerstat.find_all_index(np_type_fool, "PERSON")
                o_location_indexes      = nerstat.find_all_index(np_type_fool, "LOCATION")
                o_organization_indexes  = nerstat.find_all_index(np_type_fool, "ORGANIZATION")

                # boson_ner
                # for i in ["PERSON", "LOCATION", "ORGANIZATION"]:
                b_person_indexes        = nerstat.find_all_index(np_type_boson, "PERSON")
                b_location_indexes      = nerstat.find_all_index(np_type_boson, "LOCATION")
                b_organization_indexes  = nerstat.find_all_index(np_type_boson, "ORGANIZATION")


                print "second verification"

                print "c_person_indexes: ", c_person_indexes
                print "c_organization_indexes: ", c_organization_indexes

                print "l_person_indexes: ", l_person_indexes
                print "l_organization_indexes: ", l_organization_indexes

                print "h_person_indexes: ", h_person_indexes
                print "h_organization_indexes: ", h_organization_indexes

                print "f_person_indexes: ", f_person_indexes
                print "f_organization_indexes: ", f_organization_indexes

                print "o_person_indexes: ", o_person_indexes
                print "o_organization_indexes: ", o_organization_indexes

                print "b_person_indexes: ", b_person_indexes
                print "b_organization_indexes: ", b_organization_indexes

                corenlp_amount_stat = [len(c_person_indexes), len(c_location_indexes), len(c_organization_indexes)]
                ltp_amount_stat     = [len(l_person_indexes), len(l_location_indexes), len(l_organization_indexes)]
                hanlp_amount_stat   = [len(h_person_indexes), len(h_location_indexes), len(h_organization_indexes)]
                fnlp_amount_stat    = [len(f_person_indexes), len(f_location_indexes), len(f_organization_indexes)]
                fool_amount_stat    = [len(o_person_indexes), len(o_location_indexes), len(o_organization_indexes)]
                boson_amount_stat   = [len(b_person_indexes), len(b_location_indexes), len(b_organization_indexes)]


                # ------------------------------------------------
                subJsonObject["corenlp"] = corenlp_amount_stat
                subJsonObject["ltp"]     = ltp_amount_stat
                subJsonObject["hanlp"]   = hanlp_amount_stat
                subJsonObject["fnlp"]    = fnlp_amount_stat
                subJsonObject["fool"]    = fool_amount_stat
                subJsonObject["boson"]   = boson_amount_stat
                # ------------------------------------------------

                # ## 2018-01-31 set operation deleted
                # for overlap inforamtion

                bc_overlapped, bc_matched = nerstat.find_overlaps(boson_entities_info, b_person_indexes, b_location_indexes, b_organization_indexes,
                                                          corenlp_entities_info, c_person_indexes, c_location_indexes, c_organization_indexes)

                bl_overlapped, bl_matched = nerstat.find_overlaps(boson_entities_info, b_person_indexes, b_location_indexes, b_organization_indexes,
                                                          ltp_entities_info, l_person_indexes, l_location_indexes, l_organization_indexes)

                bh_overlapped, bh_matched = nerstat.find_overlaps(boson_entities_info, b_person_indexes, b_location_indexes, b_organization_indexes,
                                                          hanlp_entities_info, h_person_indexes, h_location_indexes, h_organization_indexes)

                bf_overlapped, bf_matched = nerstat.find_overlaps(boson_entities_info, b_person_indexes, b_location_indexes, b_organization_indexes,
                                                          fnlp_entities_info, f_person_indexes, f_location_indexes, f_organization_indexes)

                bo_overlapped, bo_matched = nerstat.find_overlaps(boson_entities_info, b_person_indexes, b_location_indexes, b_organization_indexes,
                                                          fool_entities_info, o_person_indexes, o_location_indexes, o_organization_indexes)

                # ------------------------------------------------
                subJsonObject["bc"] = bc_matched
                subJsonObject["bl"] = bl_matched
                subJsonObject["bh"] = bh_matched
                subJsonObject["bf"] = bf_matched
                subJsonObject["bo"] = bo_matched
                # ------------------------------------------------
                # ------------------------------------------------
                subJsonObject["bc_overlapped"] = bc_overlapped
                subJsonObject["bl_overlapped"] = bl_overlapped
                subJsonObject["bh_overlapped"] = bh_overlapped
                subJsonObject["bf_overlapped"] = bf_overlapped
                subJsonObject["bo_overlapped"] = bo_overlapped
                # subJsonObject["clh"] = clh
                # ------------------------------------------------

                print "verification 3"

                print "bc_matched", bc_matched
                print "bl_matched", bl_matched
                print "bh_matched", bh_matched
                print "bf_matched", bf_matched
                print "bo_matched", bo_matched

                print "bc_overlapped", bc_overlapped
                print "bl_overlapped", bl_overlapped
                print "bh_overlapped", bh_overlapped
                print "bf_overlapped", bf_overlapped
                print "bo_overlapped", bo_overlapped

                jsonObjArray.append(subJsonObject)

            jsonObject["stats"] = jsonObjArray
            #
            print "*" * 20
            print "writing to : test_o_" + str(i) + ".json"

            # demjson.encode_to_file("./" + str(i) + ".json", encoding="utf-8")

            with open("test_o_" + str(i) +  ".json", "w") as fp:
                json.dump(jsonObject, fp)
            print "done."

if __name__ == '__main__':
    #unittest.main()
    # 构造测试集
    suite = unittest.TestSuite()
    suite.addTest(find_overlaps("test1"))
    # 执行测试
    runner = unittest.TextTestRunner()
    runner.run(suite)
